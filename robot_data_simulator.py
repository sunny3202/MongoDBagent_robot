#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– ë¡œë´‡ ë°ì´í„° MongoDB ì‹œë®¬ë ˆì´í„° v2.0
ì‹¤ì‹œê°„ ë¡œë´‡ ì„¼ì„œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  MongoDBì— ì €ì¥í•©ë‹ˆë‹¤.
ê°œì„ ì‚¬í•­: Date íƒ€ì… ì €ì¥, ë©±ë“±ì„± ë³´ì¥, ì„±ëŠ¥ ìµœì í™”, ì¸ë±ìŠ¤ ìë™ ê´€ë¦¬, MongoDB ì‘ë‹µ ì²˜ë¦¬ ê°•í™”
"""

import json
import random
import logging
import schedule
import time
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure, DuplicateKeyError
from logging.handlers import RotatingFileHandler
import os


class MongoDBResponse:
    """MongoDB ì €ì¥ ì‘ë‹µ í´ë˜ìŠ¤ - ìƒì„¸í•œ ê²°ê³¼ ë° ì„±ëŠ¥ ì§€í‘œ"""
    def __init__(self, success: bool, inserted_id=None, 
                 modified_count=0, matched_count=0, upserted_id=None,
                 error_message=None, execution_time=0.0, 
                 operation_type="unknown"):
        self.success = success
        self.inserted_id = inserted_id
        self.modified_count = modified_count
        self.matched_count = matched_count
        self.upserted_id = upserted_id
        self.error_message = error_message
        self.execution_time = execution_time
        self.operation_type = operation_type  # "insert", "update", "upsert"
        self.timestamp = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "success": self.success,
            "inserted_id": str(self.inserted_id) if self.inserted_id else None,
            "modified_count": self.modified_count,
            "matched_count": self.matched_count,
            "upserted_id": str(self.upserted_id) if self.upserted_id else None,
            "error_message": self.error_message,
            "execution_time": round(self.execution_time, 3),
            "operation_type": self.operation_type,
            "timestamp": self.timestamp.isoformat()
        }
    
    def __str__(self) -> str:
        if self.success:
            return f"MongoDB {self.operation_type} ì„±ê³µ ({self.execution_time:.3f}ì´ˆ)"
        else:
            return f"MongoDB {self.operation_type} ì‹¤íŒ¨: {self.error_message}"


class ProcessFlowTracker:
    """í”„ë¡œì„¸ìŠ¤ í”Œë¡œìš° ì¶”ì  í´ë˜ìŠ¤"""
    def __init__(self):
        self.current_step = None
        self.step_start_time = None
        self.processed_robots = 0
        self.generated_data_points = 0
        self.errors = []
        self.steps_completed = []
        
    def start_step(self, step_name: str):
        """ë‹¨ê³„ ì‹œì‘"""
        self.current_step = step_name
        self.step_start_time = datetime.now()
        logging.info(f"ğŸ”„ ë‹¨ê³„ ì‹œì‘: {step_name}")
    
    def complete_step(self, step_name: str, success: bool = True):
        """ë‹¨ê³„ ì™„ë£Œ"""
        if self.current_step == step_name and self.step_start_time:
            duration = (datetime.now() - self.step_start_time).total_seconds()
            status = "ì™„ë£Œ" if success else "ì‹¤íŒ¨"
            logging.info(f"âœ… ë‹¨ê³„ {status}: {step_name} ({duration:.2f}ì´ˆ)")
            
            self.steps_completed.append({
                "step": step_name,
                "success": success,
                "duration": duration,
                "timestamp": datetime.now()
            })
    
    def add_error(self, error_message: str):
        """ì˜¤ë¥˜ ì¶”ê°€"""
        self.errors.append({
            "message": error_message,
            "timestamp": datetime.now(),
            "step": self.current_step
        })
    
    def increment_robot(self, data_points_count: int = 0):
        """ì²˜ë¦¬ëœ ë¡œë´‡ ìˆ˜ ì¦ê°€"""
        self.processed_robots += 1
        self.generated_data_points += data_points_count
    
    def get_current_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ì§„í–‰ ìƒí™© ë°˜í™˜"""
        return {
            "current_step": self.current_step,
            "processed_robots": self.processed_robots,
            "generated_data_points": self.generated_data_points,
            "step_duration": (datetime.now() - self.step_start_time).total_seconds() if self.step_start_time else 0,
            "errors": self.errors[-5:],  # ìµœê·¼ 5ê°œ ì˜¤ë¥˜ë§Œ
            "steps_completed": self.steps_completed,
            "success_rate": (self.processed_robots / 30 * 100) if self.processed_robots > 0 else 0
        }
    
    def reset(self):
        """ìƒíƒœ ì´ˆê¸°í™”"""
        self.current_step = None
        self.step_start_time = None
        self.processed_robots = 0
        self.generated_data_points = 0
        self.errors = []
        self.steps_completed = []

class RobotDataSimulator:
    def __init__(self, config_file: str = "simulator_config.json", target_robot_ids: List[str] = None):
        """ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”"""
        self.config = self._load_config(config_file)
        self.client = None
        self.db = None
        self.collection = None
        self.stop_requested = False  # ì •ì§€ ì‹ í˜¸ í”Œë˜ê·¸ ì¶”ê°€
        self.process_tracker = ProcessFlowTracker()  # í”„ë¡œì„¸ìŠ¤ ì¶”ì ê¸° ì¶”ê°€
        
        self._setup_logging()
        self._setup_database()
        self._ensure_indexes()
        
        # ë¡œë´‡ ID ìƒì„± (ê°œë³„ ë¡œë´‡ ëª¨ë“œ ì§€ì›)
        if target_robot_ids:
            self.robot_ids = target_robot_ids  # íŠ¹ì • ë¡œë´‡ë§Œ ì²˜ë¦¬
            logging.info(f"ğŸ¯ ê°œë³„ ë¡œë´‡ ëª¨ë“œ: {target_robot_ids}")
        else:
            self.robot_ids = [f"AGV-{i:03d}" for i in range(1, self.config['simulation']['robot_count'] + 1)]  # ì „ì²´ ë¡œë´‡ ì²˜ë¦¬
            logging.info(f"ğŸ­ ì „ì²´ ë¡œë´‡ ëª¨ë“œ: {len(self.robot_ids)}ëŒ€")
        
        self.route_names = [f"ROUTE{i}" for i in range(1, 21)]
        
        # ëœë¤ ì‹œë“œ ì„¤ì •
        if self.config['simulation'].get('random_seed') is not None:
            random.seed(self.config['simulation']['random_seed'])
        
        logging.info(f"ğŸš€ ë¡œë´‡ ë°ì´í„° ì‹œë®¬ë ˆì´í„° v2.0 ì´ˆê¸°í™” ì™„ë£Œ")
        logging.info(f"   ë¡œë´‡ ìˆ˜: {len(self.robot_ids)}")
        logging.info(f"   ì—„ê²© ëª¨ë“œ: {self.config['simulation']['strict_mode']}")
        logging.info(f"   ì •ê·œí™” ì €ì¥: {self.config['simulation']['normalized_storage']}")
        logging.info(f"   ëœë¤ ì‹œë“œ: {self.config['simulation'].get('random_seed', 'None')}")
    
    def _load_config(self, config_file: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logging.error(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file}")
            raise
        except json.JSONDecodeError as e:
            logging.error(f"ì„¤ì • íŒŒì¼ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì • (ë¡œí…Œì´ì…˜ í¬í•¨)"""
        log_config = self.config['logging']
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = os.path.dirname(log_config['file'])
        if log_dir and not os.path.exists(log_dir):
            os.makedirs(log_dir)
        
        # RotatingFileHandler ì„¤ì •
        rotating_handler = RotatingFileHandler(
            log_config['file'],
            maxBytes=log_config.get('max_size_mb', 10) * 1024 * 1024,  # MB to bytes
            backupCount=log_config.get('backup_count', 5),
            encoding='utf-8'
        )
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬ (Windows ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„° ì„¤ì •
        formatter = logging.Formatter(log_config['format'])
        rotating_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # ë¡œê±° ì„¤ì •
        logging.basicConfig(
            level=getattr(logging, log_config['level']),
            handlers=[rotating_handler, console_handler],
            force=True
        )
    
    def _setup_database(self):
        """MongoDB ì—°ê²° ì„¤ì •"""
        try:
            db_config = self.config['database']
            self.client = MongoClient(db_config['connection_string'])
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            self.client.admin.command('ping')
            
            self.db = self.client[db_config['database_name']]
            self.collection = self.db[db_config['collection_name']]
            
            logging.info(f"âœ… MongoDB ì—°ê²° ì„±ê³µ: {db_config['database_name']}.{db_config['collection_name']}")
            
        except ConnectionFailure as e:
            logging.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def _ensure_indexes(self):
        """ì¸ë±ìŠ¤ ìë™ ìƒì„± ë° ë³´ì¥"""
        try:
            if self.config['simulation']['normalized_storage']:
                # ì •ê·œí™” ëª¨ë“œ ì¸ë±ìŠ¤
                self._ensure_normalized_indexes()
            else:
                # ë‹¨ì¼ ì»¬ë ‰ì…˜ ëª¨ë“œ ì¸ë±ìŠ¤
                self._ensure_single_collection_indexes()
            
            logging.info("âœ… ì¸ë±ìŠ¤ ìƒì„±/ê²€ì¦ ì™„ë£Œ")
            
        except Exception as e:
            logging.error(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì¸ë±ìŠ¤ ì˜¤ë¥˜ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
            logging.warning("âš ï¸ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨í–ˆì§€ë§Œ ì‹œë®¬ë ˆì´í„°ëŠ” ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    def _ensure_single_collection_indexes(self):
        """ë‹¨ì¼ ì»¬ë ‰ì…˜ ëª¨ë“œ ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            # ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸
            existing_indexes = list(self.collection.list_indexes())
            index_names = [idx['name'] for idx in existing_indexes]
            
            # ìœ ë‹ˆí¬ ì¸ë±ìŠ¤ (robot_id + mission_start_date)
            unique_index_name = "robot_id_1_mission_start_date_1"
            if unique_index_name not in index_names:
                self.collection.create_index(
                    [("robot_id", 1), ("mission_start_date", 1)],
                    unique=True,
                    background=True
                )
                logging.info("âœ… ìœ ë‹ˆí¬ ì¸ë±ìŠ¤ ìƒì„±: robot_id + mission_start_date")
            
            # ì¼ë°˜ ì¸ë±ìŠ¤ë“¤
            indexes_to_create = [
                ("mission_start_date_1", [("mission_start_date", 1)]),
                ("location_site_1_location_line_1", [("location.site", 1), ("location.line", 1)]),
                ("data_points_timestamp_1", [("data_points.timestamp", 1)]),
                ("robot_id_1", [("robot_id", 1)])
            ]
            
            for index_name, index_spec in indexes_to_create:
                if index_name not in index_names:
                    self.collection.create_index(index_spec, background=True)
                    logging.info(f"âœ… ì¸ë±ìŠ¤ ìƒì„±: {index_name}")
                    
        except Exception as e:
            logging.error(f"âŒ ë‹¨ì¼ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _ensure_normalized_indexes(self):
        """ì •ê·œí™” ëª¨ë“œ ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            missions_collection = self.db['robot_missions']
            datapoints_collection = self.db['robot_data_points']
            
            # robot_missions ì¸ë±ìŠ¤
            missions_indexes = list(missions_collection.list_indexes())
            missions_index_names = [idx['name'] for idx in missions_indexes]
            
            # ìœ ë‹ˆí¬ ì¸ë±ìŠ¤
            unique_index_name = "robot_id_1_mission_start_date_1"
            if unique_index_name not in missions_index_names:
                missions_collection.create_index(
                    [("robot_id", 1), ("mission_start_date", 1)],
                    unique=True,
                    background=True
                )
                logging.info("âœ… robot_missions ìœ ë‹ˆí¬ ì¸ë±ìŠ¤ ìƒì„±")
            
            # ì¼ë°˜ ì¸ë±ìŠ¤ë“¤
            missions_indexes_to_create = [
                ("mission_start_date_1", [("mission_start_date", 1)]),
                ("location_site_1_location_line_1", [("location.site", 1), ("location.line", 1)])
            ]
            
            for index_name, index_spec in missions_indexes_to_create:
                if index_name not in missions_index_names:
                    missions_collection.create_index(index_spec, background=True)
                    logging.info(f"âœ… robot_missions ì¸ë±ìŠ¤ ìƒì„±: {index_name}")
            
            # robot_data_points ì¸ë±ìŠ¤
            datapoints_indexes = list(datapoints_collection.list_indexes())
            datapoints_index_names = [idx['name'] for idx in datapoints_indexes]
            
            # ìœ ë‹ˆí¬ ì¸ë±ìŠ¤
            datapoints_unique_index_name = "mission_id_1_timestamp_1"
            if datapoints_unique_index_name not in datapoints_index_names:
                datapoints_collection.create_index(
                    [("mission_id", 1), ("timestamp", 1)],
                    unique=True,
                    background=True
                )
                logging.info("âœ… robot_data_points ìœ ë‹ˆí¬ ì¸ë±ìŠ¤ ìƒì„±")
            
            # ì¼ë°˜ ì¸ë±ìŠ¤ë“¤
            datapoints_indexes_to_create = [
                ("robot_id_1_timestamp_1", [("robot_id", 1), ("timestamp", 1)]),
                ("timestamp_1", [("timestamp", 1)])
            ]
            
            for index_name, index_spec in datapoints_indexes_to_create:
                if index_name not in datapoints_index_names:
                    datapoints_collection.create_index(index_spec, background=True)
                    logging.info(f"âœ… robot_data_points ì¸ë±ìŠ¤ ìƒì„±: {index_name}")
                    
        except Exception as e:
            logging.error(f"âŒ ì •ê·œí™” ëª¨ë“œ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def generate_random_location(self) -> Dict[str, str]:
        """ëœë¤ ìœ„ì¹˜ ìƒì„±"""
        locations = self.config['locations']
        
        if self.config['simulation']['strict_mode']:
            # ì—„ê²© ëª¨ë“œ: ê¶Œì¥ ê°’ë§Œ ì‚¬ìš©
            return {
                'site': random.choice(locations['sites']),
                'line': random.choice(locations['lines']),
                'floor': random.choice(locations['floors']),
                'area': locations['area']
            }
        else:
            # ììœ  ëª¨ë“œ: ì›ë¬¸ ê°’ë„ í—ˆìš©
            sites = locations['sites'] + ['P']  # ì›ë¬¸ ê°’ ì¶”ê°€
            lines = locations['lines'] + ['P1L']  # ì›ë¬¸ ê°’ ì¶”ê°€
            floors = locations['floors'] + ['3F', '5F']  # ì›ë¬¸ ê°’ ì¶”ê°€
            areas = [locations['area'], 'FSF']  # ì›ë¬¸ ê°’ ì¶”ê°€
            
            return {
                'site': random.choice(sites),
                'line': random.choice(lines),
                'floor': random.choice(floors),
                'area': random.choice(areas)
            }
    
    def generate_sensor_data(self, timestamp: datetime) -> Dict[str, Any]:
        """ì„¼ì„œ ë°ì´í„° ìƒì„± (Date íƒ€ì… ì‚¬ìš©)"""
        sensor_ranges = self.config['sensor_ranges']
        
        # ê¸°ë³¸ ì„¼ì„œ ë°ì´í„° (Date íƒ€ì…ìœ¼ë¡œ ì €ì¥)
        data = {
            'timestamp': timestamp,  # datetime ê°ì²´ ì§ì ‘ ì €ì¥
            'unix_time': timestamp.timestamp(),
            'pos_x': random.randint(sensor_ranges['pos_x'][0], sensor_ranges['pos_x'][1]),
            'pos_y': random.randint(sensor_ranges['pos_y'][0], sensor_ranges['pos_y'][1]),
            'theta': random.randint(sensor_ranges['theta'][0], sensor_ranges['theta'][1]),
            'localization_score': round(random.uniform(sensor_ranges['localization_score'][0], sensor_ranges['localization_score'][1]), 2),
            'tilt_x': round(random.uniform(sensor_ranges['tilt_x'][0], sensor_ranges['tilt_x'][1]), 2),
            'tilt_y': round(random.uniform(sensor_ranges['tilt_y'][0], sensor_ranges['tilt_y'][1]), 2),
            'spm_flex_1': 0,
            'spm_flex_2': 0,
            'gtd_5000': 0,
            'NH3': round(random.uniform(sensor_ranges['NH3'][0], sensor_ranges['NH3'][1]), 2),
            'H2S': round(random.uniform(sensor_ranges['H2S'][0], sensor_ranges['H2S'][1]), 2),
            'VOCs': round(random.uniform(sensor_ranges['VOCs'][0], sensor_ranges['VOCs'][1]), 2),
            'F2': round(random.uniform(sensor_ranges['F2'][0], sensor_ranges['F2'][1]), 3),
            'HF': round(random.uniform(sensor_ranges['HF'][0], sensor_ranges['HF'][1]), 2),
            'temperature': round(random.uniform(sensor_ranges['temperature'][0], sensor_ranges['temperature'][1]), 1),
            'humidity': round(random.uniform(sensor_ranges['humidity'][0], sensor_ranges['humidity'][1]), 1),
            'illuminance': round(random.uniform(sensor_ranges['illuminance'][0], sensor_ranges['illuminance'][1]), 2),
            'noise': round(random.uniform(sensor_ranges['noise'][0], sensor_ranges['noise'][1]), 2),
            'thermal_cam_Pan': 0,
            'thermal_cam_tilt': 0,
            'thermal_cam_zoom': 0,
            'sonic_cam_pan': 0,
            'sonic_cam_Tilt': 0,  # ì›ë¬¸ ëŒ€ì†Œë¬¸ì ìœ ì§€
            'sonic_cam_zoom': 0,
            'normal_Pan': 0,
            'normal_Tilt': 0,
            'normal_Zoom': 0,
            'PTZ_Pan': 0,
            'PT7_Tilt': 0,  # ì›ë¬¸ í•„ë“œëª… ìœ ì§€
            'PTZ_Zoom': 0,
            'pillar_number': f"G{random.randint(10, 25)} D-{random.randint(1, 5)}",
            'bay_number': f"P{random.randint(0, 10):02d}",
            'shot_number': str(random.randint(1, 10)),
            'vr_image': {'$oid': f"689ad5a5869bfe5d99d68ccf"},
            'ptz_image': {'$oid': f"689ad5fdf1d60ed343922e4e"},
            'thermal_image': {'$oid': f"689ad6089fec0031f514f5e1"},
            'thermal_rawdata': {'$oid': f"689ad61606ac3c5ece7086c3"},
            'thermal_real_image': {'$oid': f"689ad62e3d11dabdfa4b881e"},
            'sonic_original_image': {'$oid': f"689ad625abeb55500dde1efd"},
            'sonic_rawdata': {'$oid': f"689ad625abeb55500dde1efd"}
        }
        
        return data
    
    def generate_data_points(self, mission_start: datetime, mission_end: datetime) -> List[Dict[str, Any]]:
        """ë¯¸ì…˜ ê¸°ê°„ ë™ì•ˆì˜ ë°ì´í„° í¬ì¸íŠ¸ ìƒì„±"""
        data_points_count = random.randint(
            self.config['simulation']['data_points_min'],
            self.config['simulation']['data_points_max']
        )
        
        data_points = []
        mission_duration = (mission_end - mission_start).total_seconds()
        
        for i in range(data_points_count):
            # ë¯¸ì…˜ ê¸°ê°„ ë‚´ ê· ë“± ë¶„í¬
            time_offset = (mission_duration / (data_points_count - 1)) * i if data_points_count > 1 else 0
            timestamp = mission_start + timedelta(seconds=time_offset)
            
            data_point = self.generate_sensor_data(timestamp)
            data_points.append(data_point)
        
        return data_points
    
    def generate_mission_data(self, robot_id: str, start_time: datetime) -> Dict[str, Any]:
        """ë‹¨ì¼ ë¯¸ì…˜ ë°ì´í„° ìƒì„± (Date íƒ€ì… ì‚¬ìš©)"""
        # ë¯¸ì…˜ ì§€ì†ì‹œê°„ (4~10ë¶„)
        duration_minutes = random.randint(
            self.config['simulation']['mission_duration_min'],
            self.config['simulation']['mission_duration_max']
        )
        end_time = start_time + timedelta(minutes=duration_minutes)
        
        # ë°°í„°ë¦¬ ìƒíƒœ
        battery_start = random.randint(
            self.config['battery']['start_min'],
            self.config['battery']['start_max']
        )
        battery_drain = random.randint(
            self.config['battery']['drain_min'],
            self.config['battery']['drain_max']
        )
        battery_end = max(0, battery_start - battery_drain)
        
        # ë¯¸ì…˜ ë°ì´í„° ìƒì„± (Date íƒ€ì…ìœ¼ë¡œ ì €ì¥)
        mission_data = {
            'robot_id': robot_id,
            'mission_start_date': start_time,  # datetime ê°ì²´ ì§ì ‘ ì €ì¥
            'mission_end_date': end_time,
            'mission_start_battery_state': battery_start,
            'mission_end_battery_state': battery_end,
            'route_name': random.choice(self.route_names),
            'location': self.generate_random_location(),
            'data_points': self.generate_data_points(start_time, end_time),
            'simulated_at': datetime.now()  # datetime ê°ì²´ ì§ì ‘ ì €ì¥
        }
        
        return mission_data
    
    def generate_time_based_missions(self, base_time: datetime) -> List[Dict[str, Any]]:
        """10ë¶„ ë‹¨ìœ„ ê¸°ì¤€ìœ¼ë¡œ ë¯¸ì…˜ ìƒì„± (ì •í™•í•œ ê·¸ë¦¬ë“œ ìŠ¤ëƒ…)"""
        missions = []
        time_grid = self.config['simulation']['time_grid_minutes']
        
        # 10ë¶„ ê·¸ë¦¬ë“œë¡œ ìŠ¤ëƒ…
        base = base_time - timedelta(
            minutes=base_time.minute % time_grid,
            seconds=base_time.second,
            microseconds=base_time.microsecond
        )
        
        for robot_id in self.robot_ids:
            # 10ë¶„ ê·¸ë¦¬ë“œ ë‚´ ëœë¤ ì˜¤í”„ì…‹ (ë™ì‹œ ì¶œë°œ ë°©ì§€)
            offset_minutes = random.randint(0, time_grid - 1)
            start_time = base + timedelta(minutes=offset_minutes)
            
            mission_data = self.generate_mission_data(robot_id, start_time)
            missions.append(mission_data)
        
        return missions
    
    def save_to_mongodb(self, mission_data: Dict[str, Any]) -> MongoDBResponse:
        """MongoDBì— ë¯¸ì…˜ ë°ì´í„° ì €ì¥ (ë©±ë“±ì„± ë³´ì¥) - ê°•í™”ëœ ì‘ë‹µ ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            if self.config['simulation']['normalized_storage']:
                result = self._save_normalized_enhanced(mission_data)
            else:
                result = self._save_single_collection_enhanced(mission_data)
            
            execution_time = time.time() - start_time
            result.execution_time = execution_time
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}"
            logging.error(f"âŒ {error_msg}")
            self.process_tracker.add_error(error_msg)
            
            return MongoDBResponse(
                success=False,
                error_message=error_msg,
                execution_time=execution_time,
                operation_type="save_failed"
            )
    
    def _save_single_collection_enhanced(self, mission_data: Dict[str, Any]) -> MongoDBResponse:
        """ë‹¨ì¼ ì»¬ë ‰ì…˜ì— ì €ì¥ (ë©±ë“±ì„± ë³´ì¥) - ê°•í™”ëœ ì‘ë‹µ ì²˜ë¦¬"""
        try:
            # ì¤‘ë³µ ì²´í¬ ë° ì—…ì„œíŠ¸
            filter_criteria = {
                "robot_id": mission_data['robot_id'],
                "mission_start_date": mission_data['mission_start_date']
            }
            
            result = self.collection.replace_one(filter_criteria, mission_data, upsert=True)
            
            # ê²°ê³¼ ë¶„ì„
            if result.upserted_id:
                operation_type = "insert"
                logging.info(f"âœ… {mission_data['robot_id']} ìƒˆ ë¯¸ì…˜ ì‚½ì…")
            elif result.modified_count > 0:
                operation_type = "update"
                logging.info(f"âœ… {mission_data['robot_id']} ê¸°ì¡´ ë¯¸ì…˜ ì—…ë°ì´íŠ¸")
            else:
                operation_type = "no_change"
                logging.info(f"â„¹ï¸ {mission_data['robot_id']} ë¯¸ì…˜ ë³€ê²½ ì—†ìŒ")
            
            return MongoDBResponse(
                success=True,
                inserted_id=result.upserted_id,
                modified_count=result.modified_count,
                matched_count=result.matched_count,
                upserted_id=result.upserted_id,
                operation_type=operation_type
            )
            
        except Exception as e:
            error_msg = f"ë‹¨ì¼ ì»¬ë ‰ì…˜ ì €ì¥ ì‹¤íŒ¨: {str(e)}"
            logging.error(f"âŒ {error_msg}")
            return MongoDBResponse(
                success=False,
                error_message=error_msg,
                operation_type="single_collection_error"
            )
    
    def _save_normalized_enhanced(self, mission_data: Dict[str, Any]) -> MongoDBResponse:
        """ì •ê·œí™”ëœ êµ¬ì¡°ë¡œ ì €ì¥ (ë©±ë“±ì„± ë³´ì¥ + insert_many ìµœì í™”) - ê°•í™”ëœ ì‘ë‹µ ì²˜ë¦¬"""
        try:
            missions_collection = self.db['robot_missions']
            datapoints_collection = self.db['robot_data_points']
            
            # ë¯¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥ (ë©±ë“±ì„± ë³´ì¥)
            mission_meta = {k: v for k, v in mission_data.items() if k != 'data_points'}
            
            # ì—…ì„œíŠ¸ë¡œ ì¤‘ë³µ ë°©ì§€
            filter_criteria = {
                "robot_id": mission_meta['robot_id'],
                "mission_start_date": mission_meta['mission_start_date']
            }
            
            mission_result = missions_collection.replace_one(filter_criteria, mission_meta, upsert=True)
            
            # ë¯¸ì…˜ ID ê²°ì •
            if mission_result.upserted_id:
                mission_id = mission_result.upserted_id
                operation_type = "insert_normalized"
                logging.info(f"âœ… {mission_data['robot_id']} ìƒˆ ì •ê·œí™” ë¯¸ì…˜ ì‚½ì…")
            else:
                # ê¸°ì¡´ ë¯¸ì…˜ ì°¾ê¸°
                existing_mission = missions_collection.find_one(filter_criteria)
                mission_id = existing_mission['_id']
                operation_type = "update_normalized"
                logging.info(f"âœ… {mission_data['robot_id']} ê¸°ì¡´ ì •ê·œí™” ë¯¸ì…˜ ì—…ë°ì´íŠ¸")
                
                # ê¸°ì¡´ ë°ì´í„° í¬ì¸íŠ¸ ì‚­ì œ
                delete_result = datapoints_collection.delete_many({"mission_id": mission_id})
                logging.info(f"ğŸ—‘ï¸ {delete_result.deleted_count}ê°œ ê¸°ì¡´ ë°ì´í„° í¬ì¸íŠ¸ ì‚­ì œ")
            
            # ë°ì´í„° í¬ì¸íŠ¸ ì¼ê´„ ì‚½ì… (insert_many ìµœì í™”)
            datapoints_inserted = 0
            if mission_data['data_points']:
                data_points_batch = []
                for dp in mission_data['data_points']:
                    dp_copy = dp.copy()
                    dp_copy['mission_id'] = mission_id
                    dp_copy['robot_id'] = mission_data['robot_id']
                    data_points_batch.append(dp_copy)
                
                if data_points_batch:
                    dp_result = datapoints_collection.insert_many(data_points_batch, ordered=False)
                    datapoints_inserted = len(dp_result.inserted_ids)
                    logging.info(f"ğŸ“Š {datapoints_inserted}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ì‚½ì…")
            
            return MongoDBResponse(
                success=True,
                inserted_id=mission_result.upserted_id,
                modified_count=mission_result.modified_count + datapoints_inserted,
                matched_count=mission_result.matched_count,
                upserted_id=mission_result.upserted_id,
                operation_type=operation_type
            )
            
        except Exception as e:
            error_msg = f"ì •ê·œí™” ì €ì¥ ì‹¤íŒ¨: {str(e)}"
            logging.error(f"âŒ {error_msg}")
            return MongoDBResponse(
                success=False,
                error_message=error_msg,
                operation_type="normalized_error"
            )
    
    def generate_and_save_missions(self):
        """ë¯¸ì…˜ ìƒì„± ë° ì €ì¥ (í”„ë¡œì„¸ìŠ¤ ì¶”ì  í¬í•¨)"""
        current_time = datetime.now()
        logging.info(f"ğŸ”„ ë¯¸ì…˜ ìƒì„± ì‹œì‘: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # í”„ë¡œì„¸ìŠ¤ ì¶”ì  ì´ˆê¸°í™”
        self.process_tracker.reset()
        
        # 1ë‹¨ê³„: ë¯¸ì…˜ ìƒì„±
        self.process_tracker.start_step("mission_generation")
        missions = self.generate_time_based_missions(current_time)
        self.process_tracker.complete_step("mission_generation", True)
        
        # 2ë‹¨ê³„: ë°ì´í„° ì €ì¥
        self.process_tracker.start_step("data_saving")
        success_count = 0
        total_execution_time = 0.0
        operation_stats = {"insert": 0, "update": 0, "error": 0}
        
        for i, mission in enumerate(missions):
            robot_id = mission['robot_id']
            data_points_count = len(mission.get('data_points', []))
            
            # MongoDB ì €ì¥ (ê°•í™”ëœ ì‘ë‹µ ì²˜ë¦¬)
            result = self.save_to_mongodb(mission)
            
            if result.success:
                success_count += 1
                total_execution_time += result.execution_time
                operation_stats[result.operation_type.split("_")[0]] = operation_stats.get(result.operation_type.split("_")[0], 0) + 1
                
                logging.info(f"âœ… {robot_id} {result}")
                self.process_tracker.increment_robot(data_points_count)
            else:
                operation_stats["error"] += 1
                logging.error(f"âŒ {robot_id} {result}")
                self.process_tracker.add_error(f"{robot_id}: {result.error_message}")
        
        self.process_tracker.complete_step("data_saving", success_count == len(missions))
        
        # ê²°ê³¼ í†µê³„
        avg_execution_time = total_execution_time / len(missions) if missions else 0
        logging.info(f"ğŸ“Š ë¯¸ì…˜ ìƒì„± ì™„ë£Œ: {success_count}/{len(missions)} ì„±ê³µ")
        logging.info(f"â±ï¸ í‰ê·  ì €ì¥ ì‹œê°„: {avg_execution_time:.3f}ì´ˆ")
        logging.info(f"ğŸ“ˆ ì‘ì—… í†µê³„: {operation_stats}")
        
        return {
            "success_count": success_count,
            "total_missions": len(missions),
            "avg_execution_time": avg_execution_time,
            "operation_stats": operation_stats,
            "process_status": self.process_tracker.get_current_status()
        }
    
    def get_statistics(self):
        """í˜„ì¬ ë°ì´í„° í†µê³„ ì¡°íšŒ"""
        try:
            if self.config['simulation']['normalized_storage']:
                return self._get_normalized_statistics()
            else:
                return self._get_single_collection_statistics()
        except Exception as e:
            logging.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def _get_single_collection_statistics(self):
        """ë‹¨ì¼ ì»¬ë ‰ì…˜ í†µê³„"""
        total_docs = self.collection.count_documents({})
        logging.info(f"ğŸ“Š í˜„ì¬ ì´ ë¬¸ì„œ ìˆ˜: {total_docs}")
        
        # ë¡œë´‡ë³„ í†µê³„
        pipeline = [
            {"$group": {
                "_id": "$robot_id",
                "count": {"$sum": 1},
                "avg_battery_start": {"$avg": "$mission_start_battery_state"},
                "avg_battery_end": {"$avg": "$mission_end_battery_state"}
            }},
            {"$sort": {"_id": 1}}
        ]
        
        robot_stats = list(self.collection.aggregate(pipeline))
        logging.info(f"ğŸ¤– ë¡œë´‡ë³„ í†µê³„:")
        for stat in robot_stats:
            logging.info(f"   {stat['_id']}: {stat['count']}ê°œ ë¯¸ì…˜")
        
        return total_docs
    
    def _get_normalized_statistics(self):
        """ì •ê·œí™” ëª¨ë“œ í†µê³„"""
        missions_collection = self.db['robot_missions']
        datapoints_collection = self.db['robot_data_points']
        
        total_missions = missions_collection.count_documents({})
        total_datapoints = datapoints_collection.count_documents({})
        
        logging.info(f"ğŸ“Š ì •ê·œí™” ëª¨ë“œ í†µê³„:")
        logging.info(f"   ì´ ë¯¸ì…˜ ìˆ˜: {total_missions}")
        logging.info(f"   ì´ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜: {total_datapoints}")
        
        # ë¡œë´‡ë³„ í†µê³„
        pipeline = [
            {"$lookup": {
                "from": "robot_data_points",
                "localField": "_id",
                "foreignField": "mission_id",
                "as": "data_points"
            }},
            {"$project": {
                "robot_id": 1,
                "data_point_count": {"$size": "$data_points"}
            }},
            {"$group": {
                "_id": "$robot_id",
                "mission_count": {"$sum": 1},
                "total_data_points": {"$sum": "$data_point_count"}
            }},
            {"$sort": {"_id": 1}}
        ]
        
        robot_stats = list(missions_collection.aggregate(pipeline))
        logging.info(f"ğŸ¤– ë¡œë´‡ë³„ í†µê³„:")
        for stat in robot_stats:
            logging.info(f"   {stat['_id']}: {stat['mission_count']}ê°œ ë¯¸ì…˜, {stat['total_data_points']}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        
        return total_missions
    
    def run_simulator(self):
        """ì‹œë®¬ë ˆì´í„° ì‹¤í–‰"""
        logging.info("ğŸš€ ë¡œë´‡ ë°ì´í„° ì‹œë®¬ë ˆì´í„° v2.0 ì‹œì‘")
        
        # ì´ˆê¸° í†µê³„
        self.get_statistics()
        
        # ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
        mission_interval = self.config['scheduling']['mission_interval_minutes']
        schedule.every(mission_interval).minutes.do(self.generate_and_save_missions)
        
        logging.info(f"â° ìŠ¤ì¼€ì¤„ ì„¤ì •: {mission_interval}ë¶„ë§ˆë‹¤ ë¯¸ì…˜ ìƒì„±")
        
        try:
            while not self.stop_requested:  # ì •ì§€ ì‹ í˜¸ í™•ì¸
                schedule.run_pending()
                time.sleep(1)
                
                # ì •ì§€ ì‹ í˜¸ê°€ ìˆìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ
                if self.stop_requested:
                    logging.info("ğŸ›‘ ì •ì§€ ì‹ í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                    break
                    
        except KeyboardInterrupt:
            logging.info("ğŸ›‘ ì‹œë®¬ë ˆì´í„° ì¤‘ì§€ë¨ (KeyboardInterrupt)")
        finally:
            self.client.close()
            logging.info("ğŸ”Œ MongoDB ì—°ê²° ì¢…ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë¡œë´‡ ë°ì´í„° MongoDB ì‹œë®¬ë ˆì´í„° v2.0')
    parser.add_argument('--config', default='simulator_config.json', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--strict', action='store_true', help='ì—„ê²© ëª¨ë“œ (ê¶Œì¥ ê°’ë§Œ ì‚¬ìš©)')
    parser.add_argument('--normalized', action='store_true', help='ì •ê·œí™” ì €ì¥ ëª¨ë“œ')
    parser.add_argument('--interval', type=int, help='ë¯¸ì…˜ ìƒì„± ê°„ê²© (ë¶„)')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (1íšŒ ì‹¤í–‰)')
    parser.add_argument('--seed', type=int, help='ëœë¤ ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥ì„±)')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ë¡œê·¸)')
    
    args = parser.parse_args()
    
    try:
        # ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”
        simulator = RobotDataSimulator(args.config)
        
        # ëª…ë ¹í–‰ ì˜µì…˜ ì ìš©
        if args.strict:
            simulator.config['simulation']['strict_mode'] = True
            logging.info("ğŸ”’ ì—„ê²© ëª¨ë“œ í™œì„±í™”")
        
        if args.normalized:
            simulator.config['simulation']['normalized_storage'] = True
            logging.info("ğŸ“Š ì •ê·œí™” ì €ì¥ ëª¨ë“œ í™œì„±í™”")
        
        if args.interval:
            simulator.config['scheduling']['mission_interval_minutes'] = args.interval
            logging.info(f"â° ë¯¸ì…˜ ê°„ê²© ë³€ê²½: {args.interval}ë¶„")
        
        if args.seed is not None:
            simulator.config['simulation']['random_seed'] = args.seed
            random.seed(args.seed)
            logging.info(f"ğŸ² ëœë¤ ì‹œë“œ ì„¤ì •: {args.seed}")
        
        if args.debug:
            logging.getLogger().setLevel(logging.DEBUG)
            logging.info("ğŸ” ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”")
        
        if args.test:
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 1íšŒ ì‹¤í–‰
            logging.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰")
            simulator.generate_and_save_missions()
            simulator.get_statistics()
        else:
            # ì •ìƒ ëª¨ë“œ: ì§€ì† ì‹¤í–‰
            simulator.run_simulator()
            
    except Exception as e:
        logging.error(f"âŒ ì‹œë®¬ë ˆì´í„° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
